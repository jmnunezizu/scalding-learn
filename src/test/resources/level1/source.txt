1	Apache Hadoop is an open-source software framework that supports data-intensive distributed
2	applications, licensed under the Apache v2 license. It supports the running of applications
3	on large clusters of commodity hardware. The Hadoop framework transparently provides both
4	reliability and data motion to applications. Hadoop implements a computational paradigm
5	named map/reduce, where the application is divided into many small fragments of work, each of
6	which may be executed or re-executed on any node in the cluster. In addition, it provides
7	a distributed file system that stores data on the compute nodes, providing very high aggregate
8	bandwidth across the cluster. Both map/reduce and the distributed file system are designed so
9	that node failures are automatically handled by the framework.[1] It enables applications to work
10	with thousands of computation-independent computers and petabytes of data. Hadoop was derived from
11	Google's MapReduce and Google File System (GFS) papers.